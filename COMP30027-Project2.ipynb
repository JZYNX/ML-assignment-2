{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The University of Melbourne, School of Computing and Information Systems\n",
    "\n",
    "# COMP30027 Machine Learning, 2024 Semester 1\n",
    "## Project 2: IMDB Movie Rating Prediction\n",
    "\n",
    "The goal of this project is to build and critically analyze supervised machine learning methods for predicting IMDB movie ratings based on various predictor variables that include movie-title, duration, director and actor(s) names and facebook likes, keywords, genre, country, budget, and others. There are five possible outcomes 0 being the lowest and 4 being the highest.\n",
    "\n",
    "This assignment aims to reinforce the largely theoretical lecture concepts surrounding data representation, classifier construction, evaluation and error analysis, by applying them to an open-ended problem. You will also have an opportunity to practice your general problem-solving skills, written communication skills, and critical thinking skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# general\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# visualisation\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data into Dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and testing dataset into dataframes\n",
    "train_df = pd.read_csv(\"project_data/train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"project_data/test_dataset.csv\")\n",
    "\n",
    "# Separate features and class for training df\n",
    "X_train = train_df.drop(columns=[\"imdb_score_binned\"])\n",
    "y_train = train_df[\"imdb_score_binned\"]\n",
    "\n",
    "# Test dataset only contains features without labels \n",
    "X_test = test_df\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing steps for both numerical and text data\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'knn__metric': 'manhattan', 'knn__n_neighbors': 9, 'preprocessor__num__scaler': StandardScaler()}\n",
      "Best Accuracy: 0.6566805266805267\n",
      "Validation Accuracy with Best Model: 0.6888519134775375\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with preprocessing and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'preprocessor__num__scaler': [StandardScaler(), MinMaxScaler()],  # Different scaling methods\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],  # Different values of k\n",
    "    'knn__metric': ['euclidean', 'manhattan']  # Different distance metrics\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)\n",
    "\n",
    "# Evaluate on the validation set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "val_accuracy = accuracy_score(y_val, best_model.predict(X_val))\n",
    "print(\"Validation Accuracy with Best Model:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5940099833610649\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing steps\n",
    "imputer = SimpleImputer(strategy='mean') \n",
    "feature_selector = SelectKBest(score_func=f_classif, k=8)  \n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', imputer),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "accuracy = pipeline.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'feature_selector__k': 8, 'imputer__strategy': 'mean'}\n",
      "Best Accuracy: 0.6745746708246708\n",
      "Validation Accuracy with Best Model: 0.6788685524126455\n"
     ]
    }
   ],
   "source": [
    "# Define feature selection, imputation, and SVM classifier\n",
    "imputer = SimpleImputer()\n",
    "feature_selector = SelectKBest(score_func=f_classif)\n",
    "classifier = SVC()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', imputer),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'feature_selector__k': [5, 8, 10] \n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)\n",
    "\n",
    "# Evaluate on the validation set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "val_accuracy = best_model.score(X_val, y_val)\n",
    "print(\"Validation Accuracy with Best Model:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
